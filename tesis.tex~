% Created 2022-03-01 mar 20:55
% Intended LaTeX compiler: pdflatex
\documentclass[twoside]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\input{mytitle}
\author{Jonatan Ahumada Fernández}
\date{\today}
\title{Modelo de literariedad usando redes semánticas y n-gramas}
\hypersetup{
 pdfauthor={Jonatan Ahumada Fernández},
 pdftitle={Modelo de literariedad usando redes semánticas y n-gramas},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.2 (Org mode 9.4.4)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

\section{FORMULACIÓN DEL PROBLEMA}
\label{sec:orgbb0ed36}
\subsection{Introducción}
\label{sec:org1e1402a}

¿Qué constituye la esencia de un texto? ¿Qué diferencia un texto
considerado 'literario' de aquél que no lo es? Esta pregunta se ha
planteado en áreas como los estudios literarios y la lingüística
\cite{eijembaum2010teoria}. Particularmente, la escuela denominada
'formalismo ruso' planteó que el objeto de estudio de la literatura,
no \emph{podría} ser la belleza, la relevancia histórica o el valor
pragmático de un texto. Más bien, su objeto de estudio \emph{debe} recaer
en un aspecto más 'objetivo': su \emph{literariedad}.  Como su nombre
sugiere, los formalistas se abocaron a formular una definición
'objetiva' y 'concreta' del fenómeno literario y adoptaron los --en
ese entonces-- modernos métodos de la buyente disciplina de la
linguística.

Siendo este el caso, ¿no es, por consiguiente, factible que un
autómata pueda medir y presentar tales características presuntamente
formales con las actuales herramientas informáticas? ¿Cómo se podría
traducir la noción de \emph{literariedad} a un algoritmo que pueda ejecutar
una máquina?


\subsection{Planteamiento del problema}
\label{sec:org4b42e9f}
Roman Jakobson propone que la \emph{literariedad} de un texto está dada por
dos componentes de lenguaje: la diacronía y la sincronía. Estos
elementos fueron expandidos de la teoría linguística de Saussure.
Más tarde, puestos en el contexto del análisis de la poesía,
Jakobson renombró esos dos ejes como \emph{metáfora} y \emph{metonímia}, en su texto
"Linguística y poética". 



\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./assets/clasificacion_saussure.png}
\caption{Distinción entre sincronía y diacronía}
\end{figure}

¿Es posible  modelar algorítmicamente  tales conceptos? Según
Jakobson, en el estudio de la \emph{literariedad} se omite el factor emisor
y factor receptor. Tan solo se centra en el mensaje. Representado
 únicamente a través de un \emph{medio} particular: en este caso, la palabra escrita.
Es, por lo tanto,  \emph{factible} que un autómata pueda medir y presentar tales
características. 

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./assets/factores_comunicacion.png}
\caption{Factores de comunicación de Roman Jakobson \cite{jakobson1981linguistica}}
\end{figure}

Saussure ofrece ya un modelo cualitativo muy bien esbozado en teoría,
que es el que luego Jakobson utilizará para definir la literariaded.
Sin embargo, aunque existe un planteamiento cualitativo del problema,
no se halló en la bibliografía consultada un modelo computacional que
modelara el concepto y lo implementara. 

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./assets/delimitacion_saussure.png}
\caption{Modelo cualitativo inicial expuesto por Ferdinand De Saussure tomado de \cite{eijembaum2010teoria}}
\end{figure}

Preliminarmente, se puede observar que el modelo de Saussure se
fundamenta en una estructura bastante familiar en la computación: la
secuencia \cite{alonso1945curso}. Así, el objetivo de este trabajo es modelar e implementar el
modelo de \emph{literariedad} de Roman Jakobson utilizando redes semánticas
y n-gramas.


\subsection{Justificacón}
\label{sec:orge257629}

Si bien existen infinitas operaciones realizables sobre un texto
computarizado, hay pocas que tengan un enfoque humanístico, sea
este linguístico, literario o estético. Este
enfoque busca generar una mayor comprensión del fenómeno literario,
en contraposición a los enfoques 'típicos' --y hoy en día
indispensables-- de procesamiento de lenguaje: extracción de
información, clasificación con base a un modelo predictivo, entre
muchos otros \cite{gelbukh2004}.

Más aún, dentro de este subcunjunto reducido, pocos están guiados por
aquello que Gelbuhk llama 'la ciencia fundamental'. A saber, la
linguística. En otras palabras, hay un vacío en el campo de la
linguística computacional en lo que se refiere a modelos que procuran
cuantificar esta perspectiva.

Tal vacío genera que el estudio académico de la literatura no pueda
sustentarse en datos 'duros' o ,por lo menos, cuantitativos propias
del método científico. Por otro lado, los diversas y posibles formas
de calcular la 'creatividad', la 'rima' o la 'belleza' de un texto,
propuesto por otros investigadores, pueden considerarse casuísticos,
acoplados a las objetivos y circunstancias de cada investigación en
particular, desde la perspectiva de la linguística general.

Así, se necesita un modelo de la \emph{literariedad} que exprese
concretamente la metáfora y la metonimia. Bien sea para ampliar las
aplicaciones de la linguistica computacional o para someter a
escrutinio los planteamientos de la teoría.

En esta investigación se formulará y evaluará un modelo para obtener
una medida cuantitativa para el concepto de \emph{literariedad} de Roman
Jakobson utilizando redes semánticas y n-gramas. De este modo, la
presente investigación respondería a la pregunta ¿Cómo medir
computarizadamente la \emph{literariedad} de un texto según el marco de la
lingüística de Jakobson?

\subsubsection{\textbf{Palabras clave:}}
\label{sec:org3a61cef}
NLP, computational linguistics, literariness,literary theory, poetics, theory of formal method

\subsubsection{\textbf{Área de conocimiento:}}
\label{sec:orga359a44}

Lingüística computacional

\subsection{Alcances y delimitaciones:}
\label{sec:org2f6f1b3}

Para computar una métrica de \emph{literariedad} será necesario comparar
un \emph{corpus objetivo} con respecto a un \emph{corpus de referencia,} este
último representará el ‘uso corriente de la lengua'. La primera
limitación de este trabajo es que no se compilará un corpus propio, sino
que partirá de los de acceso libre. La mayoría de estos se encuentran en
inglés. Por este motivo, el corpus de referencia más a la mano es
WordNet, que al ser una ontología ya contiene las anotaciones necesarias
para mi objetivo. A saber, una lista de sinónimos por palabras. Por otro
lado, el corpus objetivo no tiene que estar anotado (utilizaré un
PlainTextCorpus), pero de algún modo tiene que ser razonable su
comparación con el corpus objetivo. Por ejemplo, los resultados del
modelo serían muy difíciles de evaluar si la relación entre corpus
objetivo y de referencia sobrepasa los 2 siglos, dada la naturaleza
fluida de la lengua.

La segunda limitación concierne a la formulación de los algoritmos en sí
mismos. Me limitaré a formular los modelos más naive posibles. Por
ejemplo, (retomando el ejemplo previo) dada una palabra se considerará
un sinónimo todas las palabras listadas como tal en el corpus de
referencia, sin considerar los sub-problemas que esto podría conllevar.

En general, el alcance de este proyecto es formular e implementar un
modelo general que muestre cómo sería viable implementar el concepto de
\emph{literariedad}, sin ahondar en los detalles que se desprenden de cada
fase del flujo de NLP (por ejemplo, ¿cómo tokenizar?, ¿Qué peso tendrían
las diferentes partes de una oración en el computo final, etc).

\section{OBJETIVO GENERAL}
\label{sec:org308a635}
Diseñar e implementar un modelo que, dado un corpus de texto, produzca
indicadores para el concepto de \emph{literariedad} que plantea Roman Jakobson.

\section{OBJETIVOS ESPECÍFICOS}
\label{sec:orgbe5dc83}

\begin{enumerate}
\item Construir el corpus necesario para representar el \emph{eje sincrónico}
\item Diseñar e implementar el algoritmo para calcular la \emph{metáfora} sobre un corpus
\item Diseñar e implementar algoritmo para calcular la \emph{metonimia} sobre un corpus
\item Seleccionar y unir los textos que serán procesados (corpus objetivo) por el algoritmo
\item Correr el algoritmo sobre los corpus objetivo
\item Evaluar el algoritmo de manera cuantitativa y cualitativa
\end{enumerate}

\section{MARCO TEÓRICO}
\label{sec:orgdffc715}

\subsection{Literariedad}
\label{sec:orgd8effa3}


La \emph{literariedad} es, según Jakobson, la cualidad de un objeto
literario en cuanto tal. Por lo tanto, la \emph{literariedad} no depende de
ningún factor extrínseco, como su emisor, su valor histórico, las
ventas de tal o cual libro, las citaciones, etc. La \emph{literariedad} se
da exclusivamente por atributos propios del fenómeno del lenguaje.

Para analizar la \emph{literariedad}, se deben analizar las dos operaciones
más básicas de la conducta verbal: \emph{la selección} y \emph{la combinación.}


\subsubsection{Selección (ver linguística sincrónica):}
\label{sec:org1ff31d8}

La selección estudia qué palabra selecciona un hablante entre las
palabras existentes de la lengua, más o menos similares y hasta
cierto punto equivalentes. La selección se basa en la sinonimia o
antonimia de una palabra. En otros términos, en su semántica.


\subsubsection{Combinación (ver linguística diacrónica):}
\label{sec:orgfe8a82b}

La combinación estudia el "entramado de la secuencia" de un
mensaje. Es decir, el mensaje considerado como una secuencia
temporal y/o ordenada de palabras. La combinación se basa en la
proximidad o, en otras palabras, en la relación de una palabra con
la que la sucede o antecede en un mensaje.



\subsection{Poética}
\label{sec:orgf4fa3d4}
La poética procura responder a la pregunta de ¿qué hace que un
mensaje (verbal o de otra naturaleza) sea una obra de arte? Lidia
principalmente con cuestiones estéticas del lenguaje. Sin embargo,
para hacer un analisis exhaustivo, la poética debe hacer uso de la
linguística, puesto que esta última estudia el lenguaje en todo su
conjunto. La \emph{literariedad} podría, entonces, considerarse un
concepto enmarcado en la poética, porque se preguntá qué hace que
un texto sea literario y por qué es distinto de otro que no lo es.

\subsection{Linguística}
\label{sec:org9c2af7e}

La lingüística es la ciencia que estudia el lenguaje.
Tradicionalmente, esta ciencia se subdivide en las ramas de fonética,
fonología, morfología, sintaxis, semántica y pragmática.

La lingüística es un campo de estudio interdisciplinar e involucra
disciplinas heterogéneas como la lógica y la neurolingüistica. Sin
embargo, se considera que hay un núcleo común llamado \emph{linguística
general}.

\subsubsection{Lingüística General:}
\label{sec:org3fa9cac}

Se conoce como lingüística general al paradigma lingüístico
establecido por Ferdinand De Saussure, también llamado \emph{modelo
diferencial del lenguaje}.

El modelo diferencial se caracteriza porque propone dos ejes
principales existentes en todo fenómeno lingüístico: el \emph{eje de
sincronía} y el \emph{eje de diacronía}.

Estos dos ejes son la base de lo que Jakobson considera \emph{selección} y
\emph{combinación}.


\subsubsection{Linguística sincrónica}
\label{sec:orgfcc2cbc}

La linguística sincrónica se ocupa de las
operaciones que realiza un hablante, sean lógicas o psicológicas,
para formar un sistema linguístico. En el
marco de esta investigación el \emph{eje sincrónico} se referirá a las
posibles palabras que un hablante pudo haber seleccionado para
expresar una misma idea. Por ejemplo, para referirse a un
niño, un hablante puede utilizar la las palabras "niño", "chico",
"jovencito", o "párvulo".


\subsubsection{Linguística diacrónica}
\label{sec:org81494e0}

La linguística diacrónica estudia los cambios sucesivos en el
lenguaje, producidos por la actividad constante del \emph{eje
sincrónico}. En la perspectiva de Jakobson, un \emph{mensaje} tiene en
sí mismo un eje diacrónico. Tal eje mide la similaridad entre cada
término del mensaje entindido como secuencia. Un ejemplo se puede
apreciar en la oracion "I like Ike". An esta se evidencia una
repetición de sonidos similares: [ay layk ayk]. La similaridad, no
está dada por el significado, sino que aquí se proyecta a lo largo
del tiempo:"(\ldots{}) para decirlo de un modo más técnico: todo
secuencia es un símil."

\subsection{Lenguaje}
\label{sec:orgf48b7ed}
En términos simples, el lenguaje es la facultad de formular y
comprender signos o símbolos, ya sean hablados, escritos,
imágenes, etc.  En otros términos, el lenguaje es una
capacidad general. Sin embargo, para Saussure, la lengua
tiene una característica doble: que es al mismo
tiempo un sistema establecido y la constante evolución
de tal sistema. Estos dos componentes son la \emph{lengua}
y el \emph{habla}.

\subsubsection{Lengua}
\label{sec:org8af0331}

La lengua (\emph{langue}) es uno de los dos componentes del
\emph{lenguaje}.  La lengua es fenómeno social y se equipara a una
\emph{cristalización} o un producto de la suma de asociaciones entre
conceptos e imagenes acústicas en la mente de los hablantes. Por
ejemplo, la lengua es lo que permite que dos hablantes bogotanos
puedan asociar en su mente el sonido de la palabra "chino" con el
concepto de "niño" o "infante", mientras que en otras partes del
mundo hispanohablante no existe tal asociación común.
En términos simples, la lengua es un entendimiento compartido de
lo que significan las palabras. La contraparte de la lengua,
es el habla. 

\subsubsection{Habla}
\label{sec:org1a4275c}
El habla (\emph{parole}) es uno de los dos componentes del
\emph{lenguaje}. El habla es el uso individual de la lengua.
Evidentemente, cuando un individuo habla puede modificar
la lengua a su antojo, porque posee la facultad del
lenguaje y jamás meramente repite el consenso de la lengua.
Como consecuencia de esto, la lengua está continuamente
siendo transformada por el habla. En términos simples,
la suma de los actos individuales de comunicacion lentamente
terminan por transformar el consenso social sobre cómo
hablar.  Por este motivo la linguística debe tener una
perspectiva doble: \emph{diacrónica} y \emph{sincrónica}.


\subsection{Lingüística Computacional}
\label{sec:orge8d3cb6}

Es la intersección entre la computación y la lingüística. Por lo
general, se preocupa acerca de cómo procesar automáticamente el
lenguaje material, para lo cual genera modelos lingüísticos sobre los
que luego se pueden definir operaciones comunes \cite{gelbukh2004}.


La lingüística computacional es en sí misma un campo amplio y
heterogéneo, pero en términos de este trabajo, me limitaré a señalar
una herramienta:

\subsubsection{NLTK}
\label{sec:org3ee3966}

El Natural Language Toolkit (NLTK) es un módulo de Python que ofrece
una interfaz para tareas comunes en la lingüística computacional. La
ventaja principal de NLTK es que se considera a sí mismo un
\emph{toolkit}. Esto significa que no impone una estructura de
procesamiento definida a la vez que ofrece un extenso abanico de
herramientas, tales como: tokenizacion, filtros, generación de
n-gramas, análisis sintáctico de oraciones, entre otras.

\subsubsection{Corpus}
\label{sec:orgcd89fcc}


Un corpus es una colección de textos auténticos que pueden ser
leídos por una máquina. Estos pueden estructurarse de muchas
formas, dependiendo de los objetivos de la investigación
\cite{indurkhya2010handbook}. Por ejemplo, pueden ser aislados (una
colección arbitraria), categorizados (una colección escogida según
algún criterio), temporales (una colección organizada
cronológicamente) o solapados (un documento puede pertenecer a
varias colecciones) \cite{bird2009natural}. Además, el formato del
corpus varía significativamente de acuerdo al objeto de la
investigación. Por ejemplo, si se desea hacer un análisis
sintáctico (de la estructura de una oración), se debe hacer un
corpus anotado con POS (Part Of Speech tag); para hacer un análisis
pragmático se utiliza una anotación pragmática, etc.

\section{MARCO REFERENCIAL}
\label{sec:org2fdd363}

El trabajo de Delmonte \cite{delmonte2013computing} presenta a
SPARSAR, un sistema para calcular automáticamente el estilo de la
poesía. SPARSAR funciona sobre sistemas previos del mismo autor, como,
por ejemplo, un analizador semántico \cite{delmonte2005venses}.
Delmonte tiene una larga trayectoria en el modelamiento de conceptos
lingüísticos "difíciles", como la prosodia y la rima en términos
cuantitativos.

El aporte principal de Delmonte fue su innovación al momento de aplicar
herramientas comunes de NLP (tokenizadores, splitters y NER) con el fin
de analizar aspectos estilísticos de un texto. Los modelos de Delmonte
son muy cercanos a la teoría lingüística y propone soluciones a aspectos
complejos del análisis lingüístico. Esta proximidad me llevo a
plantearme la pregunta ¿qué otros aspectos del lenguaje valdría la pena
modelar que aún no hayan sido abordados desde una perspectiva
computacional? Así mismo, Delmonte reporta que hay pocos trabajos en el
área con este mismo enfoque. Esta fue una inspiración para explorar más
en el tema y ofrecer un enfoque distinto, tal como él lo hizo.

Sin embargo, Delmonte no revela detalles de implementación de sus sis-
temas en los artículos revisados. Además, sus sistemas tienen una
alcance mucho mayor que el dispuesto para este trabajo, por lo que para
mayores detalles tuve que referirme a otros trabajos.

El trabajo de \cite{zuniga2017automatic} establece una métrica para
medir el grado de creatividad en la poesía, basándose en qué tanto de
la rima se conserva en la traducción de un poema con respecto al
original. Tomé de Zuñiga la idea de establecer una métrica para un
aspecto tradicionalmente cualitativo (la creatividad). Lo que
diferencia este trabajo del de Delmonte, es su aproximación
matemática. Particularmente, Zuñiga ofreció una forma naive de
calcular similitud en rima, sin necesidad de recurrir a construcciones
que requieren de recursos léxicos complejos como una ontología para
fonemas, etc.

Por último, el trabajo de \cite{kaplan2006computational} es una tesis
de pregrado sobre el cálculo del estilo de la poesía desde una
perspectiva estadística. Kaplan fue una inspiración para Delmonte, por
lo tanto debía formar parte de mi revisión bibliográfica. Kaplan
formuló un modelo que media 84 métricas distintas para cada documento,
luego transformó el modelo de 84 métricas para visualizarlo en un
espacio 3D y poder comparar distintas obras literarias. Esto inspiró
mi idea inicial de obtener una métrica más general para analizar
un texto, que no tenga que recurrir un trabajo de compilación de métricas
existentes, como lo hizo Kaplan. Tal métrica debería estar sustentada
en conceptos linguísticos, para lo cual recurre en los conceptos
presentados en el marco teórico. 

\section{DISEÑO METODOLÓGICO}
\label{sec:orgfbd3814}
El diseño metodológico seguirá --a grandes rasgos-- los pasos de la
metodología CRISP-DM, que se considera un estándar \emph{de facto} para
proyectos de minería de datos. Esta metodología ayudará organizar
el proceso de mi investigación, que vá desde el acceso a los
corpus (los datos disponibles) hasta el despliegue (la
visualización de los resultados).
\subsection{Entendimiento del negocio}
\label{sec:orge246379}

El resultado tangible del modelo de literariedad propuesto son dos
métricas cuantitativas: \emph{metáfora} y \emph{metonímia}.  Estas métricas
juntas constituiran una representación 'objetiva' del concepto
cualitativo de \emph{literariedad}.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./assets/posibles_usos.jpg}
\caption{\label{fig:posibles_usos}Entradas y salidas del algoritmo}
\end{figure}


¿Cuál sería el beneficio de obtener este resultado? Se podría comparar
las métricas de n mensajes cualesquiera y tener una medida objetiva
con las  cuales compararlas. Algunos casos de uso posible serían:

\begin{itemize}
\item determinar si un mensaje que yo he escrito es más metáforico o metonímico que otro.

\item determinar si un mensajes de una misma categoria (por ejemplo, del mismo autor, o del mismo género)
tienen medidas de métadora y metonímia similares.

\item correr grandes grupos de mensajes, por ejemplo, 'poemas de la escuela simbolistas' y compararlo
con 'poemas realistas' y verificar si hay o no una diferencia sustancial desde el punto de
vista linguístico .
\end{itemize}

Como se puede apreciar (ref:fig:posibles\textsubscript{usos}), las aplicaciones del modelo en principio
supondrían un factor adicional para ser considerado para el
estudio literario, cuya naturaleza es cualitativa. Sin embargo, si
el modelo demuestra ser efectivo, podría llegar a ser una medida
de similitud para un texto, lo que implicaría que se podría
clasificar un texto con base en su metáfora y metonímia, 


\subsection{Entendimiento de los datos}
\label{sec:orgb6cead5}

En esta sección, se enumeraran las distintas fuentes de datos,
que en este caso vendrían a ser los diferentes tipos de corpus.

\subsection{El corpus de referencia}
\label{sec:org63724fa}

Para poder cuantificar la \emph{literariedad}, se debe representar
de algún modo el concepto de lengua. Es decir, debemos suponer
un uso consensuado de la lengua desde el cual sea posible comparar
si algo es literario respecto a este consenso general o no.

No existe, como es comprensible, un corpus oficial que represente
tal concepto, puesto que supondría un enorme trabajo compilación
y de estandarización con respecto a qué formato utilizar. Por
lo tanto, se necesita construir tal corpus, que llamaré
el \emph{corpus de referencia}.

Sin embargo, sí existen corpus suficientemente grandes con
respecto a un mensaje individual que podríamos tomar
como una muestra de la lengua. Dicho de otro modo,
el corpus de referencia será una colección de textos
considerablemente más grande que el mensaje estudiado,
de tal modo que simule la relación entre la lengua (consenso social)
y habla (uso individual).


\subsection{El corpus objetivo}
\label{sec:org1cde756}


\begin{quote}
The data understanding phase of CRISP-DM involves taking a closer
look at the data available for mining. This step is critical in
avoiding unexpected problems during the next phase--data
preparation--which is typically the longest part of a project.
\end{quote}

\subsubsection{Los recursos lexicos}
\label{sec:org46d4868}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./assets/estructuras_de_corpus.png}
\caption{Diferentes estructuras de corpus}
\end{figure}

\begin{enumerate}
\item Corpus de referencia
\label{sec:org731fe1a}
El corpus de referencia es Wordnet. 
\item Corpus objetivo
\label{sec:org2aeec3d}
El corpus escogido fue el corpus de Brown porque cumplía con las siguientes criterios:
\begin{enumerate}
\item La lengua inglesa tiene una correspondiente red semántica
\item Esta categorizado, por lo que se espera observar diferencias significativas en el resultado de su procesamiento
\item Es fácilmente accesible a través de Python
\end{enumerate}
\end{enumerate}

\subsubsection{La red semántica y similaridad con Saussure}
\label{sec:org1e8f33b}
\subsubsection{Por qué utilizo el Brown Corpus}
\label{sec:org22b1762}
\subsection{Preparación de los datos}
\label{sec:org826496d}

\begin{verbatim}
Depending on your organization and its goals, data preparation typically involves the following tasks:

Merging data sets and/or records
Selecting a sample subset of data
Aggregating records
Deriving new attributes
Sorting the data for modeling
Removing or replacing blank or missing values
Splitting into training and test data sets

\end{verbatim}
\subsection{Modelamiento}
\label{sec:org9bc0cef}
\subsubsection{Selecting a modeling technique (no tengo, estoy traduciendo un modelo cualitativo --investigacion mixta--)}
\label{sec:org2d25b9e}
\subsubsection{Generating a test desing}
\label{sec:orgc3e1703}


\begin{itemize}
\item Describing the criteria for "goodness" of a model
\item Defining the data on which these criteria will be tested
\end{itemize}
\begin{enumerate}
\item Sampleo de la muestra
\label{sec:org642796e}
\begin{itemize}
\item qué textos voy a someter a procesamiento
\item por qué escogí estos textos en particular
\end{itemize}
\end{enumerate}
\subsubsection{Building the models}
\label{sec:org875023e}
\begin{enumerate}
\item Presentacion de las ecuaciones
\label{sec:orgfe70038}

      \begin{equation}
mensaje = \{ w_1, w_2, w_3, \dots , w_j \} \\
\end{equation}

\begin{equation}
vector\ semantico(w) = \{s_1, s_2, s_3, \dots, s_j \} \\
\end{equation}

\begin{equation}
uso(w) = \frac{freq(w)}{freqMedia}
\end{equation}

\begin{equation}
freqMedia = \mu(freq(corpora\ ref)
\end{equation}

\begin{equation}
indice\ metaforico(mensaje) =  \Sigma_i^j \frac{uso(w_i)}{\mu( vector\ semantico(w_i))}
\end{equation}


\begin{equation}
N = \{n_1, n_2, n_3, \dots , n_j\}
\end{equation}

\begin{equation}
met(n) = \frac{letras\ iguales}{ set(letras(n_i1) + letras(n_i2)}
\end{equation}

\begin{equation}
indice\ metonimia = \Sigma_i^j met(n_i)
\end{equation}

\item Procedimientos para indicadores
\label{sec:orgffddc81}
\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./assets/metodologia.jpg}
\caption{Procesamiento de corpus objetivo}
\end{figure}   
\item Índice Metafórico
\label{sec:org6326fb1}
\item Matriz semántica
\label{sec:org5ff55e2}


\item Matriz de uso
\label{sec:org153e571}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./assets/matrices.jpg}
\caption{Abstracciones necesarias para el índice metafórico}
\end{figure}

\item Índice Metonímico
\label{sec:orgf8fc4c1}
\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./assets/metonimia.jpg}
\caption{Abstraccciones necesarias para el indice metonímico}
\end{figure}
\end{enumerate}

\subsection{Despliegue (los notebooks?? creo que no hay despliege)}
\label{sec:org7c68837}

\begin{quote}
Deployment is the process of using your new insights to make
improvements within your organization. This can mean a formal
integration such as the implementation of a IBM® SPSS® Modeler model
producing churn scores that are then read into a data
warehouse. Alternatively, deployment can mean that you use the
insights gained from data mining to elicit change in your
organization. For example, perhaps you discovered alarming patterns in
your data indicating a shift in behavior for customers over the age
of 30. These results may not be formally integrated into your
information systems, but they will undoubtedly be useful for planning
and making marketing decisions.
\end{quote}
\section{CONCLUSIONES (Creo que esto se solapa con lo que crisp-dm llama despliege)}
\label{sec:org547633e}



\bibliographystyle{unsrt}

bibliography:\textasciitilde{}/biblio/biblio.bib
\end{document}